{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0635aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import numpy.linalg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd315690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecbb48c4",
   "metadata": {},
   "source": [
    "# Testing Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45611dfc",
   "metadata": {},
   "source": [
    "### Geometric Brownian motion\n",
    "Let S be an asset with the following dynamic \\\\\n",
    "$$\n",
    "\\frac{dS_t}{S_t} = r dt + \\sigma dWt\n",
    "$$ \n",
    "with \n",
    "$$\n",
    "r = 0.05\\\\\n",
    "\\sigma = 0.2\\\\\n",
    "S_0 = 100\n",
    "$$\n",
    "Let's consider a european call option on S\n",
    "$$\n",
    "Payoff = (S_T - K)_+\\\\\n",
    "K = 100\\\\\n",
    "T = 1\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22bf3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eu_call_BS(S, T, K, r, q, sigma,t=0):\n",
    "    d1 = (np.log(S/K) + (r - q + sigma**2/2)*(T-t)) / (sigma*np.sqrt(T-t))\n",
    "    d2 = d1 - sigma* np.sqrt(T-t)\n",
    "    return S*np.exp(-q*(T-t)) * norm.cdf(d1) - K * np.exp(-r*(T-t))* norm.cdf(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f358e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoritical Price = 10.450583572185565\n"
     ]
    }
   ],
   "source": [
    "S = 100\n",
    "T = 1\n",
    "K = 100\n",
    "r = 0.05\n",
    "q = 0\n",
    "sigma = 0.2\n",
    "th_price = eu_call_BS(S, T, K, r, q, sigma)\n",
    "print(\"Theoritical Price = %s\"%(th_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76863b5e",
   "metadata": {},
   "source": [
    "Now lets try to price our option with Monte Carlo Using an Euler discretization for the SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a228a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakConvergenceFailure(Exception):\n",
    "    pass\n",
    "\n",
    "def mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha_0, beta_0, gamma_0, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Multilevel Monte Carlo estimation.\n",
    "\n",
    "    (P, Nl, Cl) = mlmc(...)\n",
    "\n",
    "    Inputs:\n",
    "      N0:   initial number of samples    >  0\n",
    "      eps:  desired accuracy (rms error) >  0\n",
    "      Lmin: minimum level of refinement  >= 2\n",
    "      Lmax: maximum level of refinement  >= Lmin\n",
    "\n",
    "      mlmc_fn: the user low-level routine for level l estimator. Its interface is\n",
    "\n",
    "        (sums, cost) = mlmc_fn(l, N, *args, **kwargs)\n",
    "\n",
    "        Inputs:  l: level\n",
    "                 N: number of paths\n",
    "                 *args, **kwargs: optional additional user variables\n",
    "\n",
    "        Outputs: sums[0]: sum(Y)\n",
    "                 sums[1]: sum(Y**2)\n",
    "                    where Y are iid samples with expected value\n",
    "                        E[P_0]            on level 0\n",
    "                        E[P_l - P_{l-1}]  on level l > 0\n",
    "                 cost: cost of N samples\n",
    "\n",
    "      alpha ->  weak error is  O(2^{-alpha*l})\n",
    "      beta  ->  variance is    O(2^{-beta*l})\n",
    "      gamma ->  sample cost is O(2^{ gamma*l})\n",
    "\n",
    "      If alpha, beta are not positive then they will be estimated.\n",
    "\n",
    "      *args, **kwargs = optional additional user variables to be passed to mlmc_fn\n",
    "\n",
    "    Outputs:\n",
    "      P:  value\n",
    "      Nl: number of samples at each level\n",
    "      Cl: cost of samples at each level\n",
    "    \"\"\"\n",
    "\n",
    "    # Check arguments\n",
    "\n",
    "    if Lmin < 2:\n",
    "        raise ValueError(\"Need Lmin >= 2\")\n",
    "    if Lmax < Lmin:\n",
    "        raise ValueError(\"Need Lmax >= Lmin\")\n",
    "    if N0 <= 0 or eps <= 0:\n",
    "        raise ValueError(\"Need N0 > 0, eps > 0\")\n",
    "\n",
    "    # Initialisation\n",
    "\n",
    "    alpha = max(0, alpha_0)\n",
    "    beta  = max(0, beta_0)\n",
    "    gamma = max(0, gamma_0)\n",
    "\n",
    "    theta = 0.25\n",
    "\n",
    "    L = Lmin\n",
    "\n",
    "    Nl   = np.zeros(L+1)\n",
    "    suml = np.zeros((2, L+1))\n",
    "    costl = np.zeros(L+1)\n",
    "    dNl  = N0*np.ones(L+1)\n",
    "\n",
    "    while sum(dNl) > 0:\n",
    "\n",
    "        # update sample sums\n",
    "\n",
    "        for l in range(0, L+1):\n",
    "            if dNl[l] > 0:\n",
    "                (sums, cost) = mlmc_fn(l, int(dNl[l]), *args, **kwargs)\n",
    "                Nl[l]        = Nl[l] + dNl[l]\n",
    "                suml[0, l]   = suml[0, l] + sums[0]\n",
    "                suml[1, l]   = suml[1, l] + sums[1]\n",
    "                costl[l]     = costl[l] + cost\n",
    "\n",
    "        # compute absolute average, variance and cost\n",
    "\n",
    "        ml = np.abs(suml[0, :]/Nl)\n",
    "        Vl = np.maximum(0, suml[1, :]/Nl - ml**2)\n",
    "        Cl = costl/Nl\n",
    "\n",
    "        # fix to cope with possible zero values for ml and Vl\n",
    "        # (can happen in some applications when there are few samples)\n",
    "\n",
    "        for l in range(3, L+2):\n",
    "            ml[l-1] = max(ml[l-1], 0.5*ml[l-2]/2**alpha)\n",
    "            Vl[l-1] = max(Vl[l-1], 0.5*Vl[l-2]/2**beta)\n",
    "\n",
    "        # use linear regression to estimate alpha, beta, gamma if not given\n",
    "        if alpha_0 <= 0:\n",
    "            A = np.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = np.linalg.lstsq(A, np.log2(ml[1:]))[0]\n",
    "            alpha = max(0.5, -x[0])\n",
    "\n",
    "        if beta_0 <= 0:\n",
    "            A = np.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = np.linalg.lstsq(A, np.log2(Vl[1:]))[0]\n",
    "            beta = max(0.5, -x[0])\n",
    "\n",
    "        if gamma_0 <= 0:\n",
    "            A = np.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = np.linalg.lstsq(A, np.log2(Cl[1:]))[0]\n",
    "            gamma = max(0.5, x[0])\n",
    "\n",
    "        # set optimal number of additional samples\n",
    "\n",
    "        Ns = np.ceil( np.sqrt(Vl/Cl) * sum(np.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
    "        dNl = np.maximum(0, Ns-Nl)\n",
    "\n",
    "        # if (almost) converged, estimate remaining error and decide\n",
    "        # whether a new level is required\n",
    "\n",
    "        if sum(dNl > 0.01*Nl) == 0:\n",
    "            # 23/3/18 this change copes with cases with erratic ml values\n",
    "            rang = list(range(min(3, L)))\n",
    "            rem = ( np.amax(ml[[L-x for x in rang]] / 2.0**(np.array(rang)*alpha))\n",
    "                    / (2.0**alpha - 1.0) )\n",
    "            # rem = ml[L] / (2.0**alpha - 1.0)\n",
    "\n",
    "            if rem > np.sqrt(theta)*eps:\n",
    "                if L == Lmax:\n",
    "                    raise WeakConvergenceFailure(\"Failed to achieve weak convergence\")\n",
    "                else:\n",
    "                    L = L + 1\n",
    "                    Vl = np.append(Vl, Vl[-1] / 2.0**beta)\n",
    "                    Nl = np.append(Nl, 0.0)\n",
    "                    suml = np.column_stack([suml, [0, 0]])\n",
    "                    Cl = np.append(Cl, Cl[-1]*2**gamma)\n",
    "                    costl = np.append(costl, 0.0)\n",
    "\n",
    "                    Ns = np.ceil( np.sqrt(Vl/Cl) * sum(np.sqrt(Vl*Cl))\n",
    "                            / ((1-theta)*eps**2) )\n",
    "                    dNl = np.maximum(0, Ns-Nl)\n",
    "\n",
    "    # finally, evaluate the multilevel estimator\n",
    "    P = sum(suml[0,:]/Nl)\n",
    "\n",
    "    return (P, Nl, Cl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f7af7",
   "metadata": {},
   "source": [
    "Finally, let's price the option with MLMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c4ae51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlmc_fn(l,N):\n",
    "    S0 = 100\n",
    "    sigma = 0.2\n",
    "    r = 0.05\n",
    "    T = 1\n",
    "    K = 100\n",
    "    dt = 2**(-l)\n",
    "    sumY = 0\n",
    "    sumY2 = 0\n",
    "    for i in range(N):\n",
    "        Sf = S0\n",
    "        Sc = S0\n",
    "        dWf = np.sqrt(dt) * np.random.randn(int(T/dt))\n",
    "        for i in range(int(T/dt)):\n",
    "            Sf += r * Sf * dt + sigma * Sf * dWf[i]\n",
    "        Pf = np.max(Sf - K, 0)\n",
    "        \n",
    "        if l == 0 :\n",
    "            Pc = 0\n",
    "        else :\n",
    "            #dWc = dWf.reshape(-1, 2)\n",
    "            dWc = np.sqrt(dt) * np.random.randn(int(T/dt/2))\n",
    "            for i in range(int(T/dt/2)):\n",
    "                Sc += r * Sc * dt + sigma * Sc * dWc[i]\n",
    "            Pc = np.max(Sc - K, 0)\n",
    "        \n",
    "        Y = Pf# - Pc\n",
    "        sumY += Y\n",
    "        sumY2 += Y**2\n",
    "        \n",
    "    return [sumY, sumY2], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac802f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.129438893222786\n"
     ]
    }
   ],
   "source": [
    "print(mlmc_fn(10, 10000)[0][0]/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "28c85dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussama\\AppData\\Local\\Temp\\ipykernel_17464\\1355844043.py:112: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Ns = np.ceil( np.sqrt(Vl/Cl) * sum(np.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
      "C:\\Users\\oussama\\AppData\\Local\\Temp\\ipykernel_17464\\1355844043.py:112: RuntimeWarning: invalid value encountered in multiply\n",
      "  Ns = np.ceil( np.sqrt(Vl/Cl) * sum(np.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
      "C:\\Users\\oussama\\AppData\\Local\\Temp\\ipykernel_17464\\1355844043.py:136: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Ns = np.ceil( np.sqrt(Vl/Cl) * sum(np.sqrt(Vl*Cl))\n",
      "C:\\Users\\oussama\\AppData\\Local\\Temp\\ipykernel_17464\\1355844043.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  Ns = np.ceil( np.sqrt(Vl/Cl) * sum(np.sqrt(Vl*Cl))\n",
      "C:\\Users\\oussama\\AppData\\Local\\Temp\\ipykernel_17464\\1355844043.py:141: RuntimeWarning: invalid value encountered in true_divide\n",
      "  P = sum(suml[0,:]/Nl)\n"
     ]
    }
   ],
   "source": [
    "Lmin = 2\n",
    "Lmax = 1000\n",
    "N0 = 1e04\n",
    "eps = 1e-06\n",
    "gamma_0 = 2\n",
    "alpha_0 = 1\n",
    "beta_0 = 1\n",
    "\n",
    "mlmc_price = mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha_0, beta_0, gamma_0)[0]\n",
    "print(mlmc_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06ff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832ff7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
